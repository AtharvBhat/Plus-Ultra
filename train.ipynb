{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libs\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "from srresnet import srresnet\n",
    "\n",
    "from torchvision.models import vgg16_bn\n",
    "import warnings\n",
    "\n",
    "#turn off pytorch warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "batch_size = 8\n",
    "num_epochs = 1\n",
    "train_val_split_pct = 0.1\n",
    "fp_16 = False\n",
    "\n",
    "#set paths to low resolution and high resolution image folders. Make sure input and target images have same names\n",
    "low_res_images_path = \"\"\n",
    "high_res_images_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images from folders as a list and split inputs into training and validation sets\n",
    "\n",
    "#high res target images\n",
    "high_res_images_list = ImageList.from_folder(high_res_images_path)\n",
    "\n",
    "#low res input images\n",
    "low_res_images_list = ImageImageList.from_folder(low_res_images_path).split_by_rand_pct(train_val_split_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create fastai databunch and get training labels\n",
    "data = (lr_list.label_from_func(lambda x: path_fullres/x.name)).databunch(bs=batch_size)\n",
    "data.c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show sample databunch\n",
    "data.show_batch(ds_type=DatasetType.Valid, rows=batch_size, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training model\n",
    "model = srresnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature loss \n",
    "# Jeremy Howard's implementation of Perceptual Losses for Real-Time Style Transfer and Super-Resolution\n",
    "# Justin Johnson, Alexandre Alahi, Li Fei-Fei\n",
    "# https://arxiv.org/abs/1603.08155v1\n",
    "# taken from fast.ai course v3 https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres.ipynb\n",
    "\n",
    "t = data.valid_ds[0][1].data\n",
    "t = torch.stack([t,t])\n",
    "\n",
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)\n",
    "\n",
    "base_loss = F.l1_loss\n",
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "\n",
    "requires_grad(vgg_m, False)\n",
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\n",
    "\n",
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()\n",
    "        \n",
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create fast.ai Learner\n",
    "\n",
    "#weight decay\n",
    "wd = 1e-3\n",
    "\n",
    "#create learner object\n",
    "learn = Learner(data,\n",
    "                model,\n",
    "                wd = wd,\n",
    "                loss_func=feat_loss,\n",
    "                callback_fns=LossMetrics)\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mixed precision training\n",
    "if fp_16 == True : learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find appropriate learning rate\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set appropriate Learning rate from the plot , if you donot understand the plot , 1e-4 usually works from my observations\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit !\n",
    "learn.fit(num_epochs, lr)\n",
    "learn.save(\"NAME OF MODEL\")\n",
    "learn.show_results(rows=batch_size, imgsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export model for inferencing.\n",
    "#We donot need vgg16 weights and loss functions for inferencing.\n",
    "#hence we can recreate our learner without feature loss before exporting as this significantly reduces the model size\n",
    "learn = Learner(data,\n",
    "                model,\n",
    "                wd = wd,\n",
    "                loss_func=base_loss)\n",
    "#load weights\n",
    "learn.load(\"NAME OF MODEL\")\n",
    "learn.export(\"NAME OF MODEL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
